
 Run on time: 2025-12-01 16:41:30.150403

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : HAND_GESTURE
	 batch_size           : 64
	 architecture         : VGG16
	 learning_rate        : 0.01
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 50
	 lr_interval          : [30, 40, 45]
	 lr_reduce            : 10
	 optimizer            : SGD
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.3
	 kernel_size          : 3
	 devices              : 0
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3027, train_acc: 0.0989 test_loss: 2.3023, test_acc: 0.1000, best: 0.1000, time: 0:01:16
 Epoch: 2, lr: 1.0e-02, train_loss: 2.3019, train_acc: 0.0975 test_loss: 2.2999, test_acc: 0.1000, best: 0.1000, time: 0:01:20
 Epoch: 3, lr: 1.0e-02, train_loss: 2.2584, train_acc: 0.1203 test_loss: 1.7992, test_acc: 0.4190, best: 0.4190, time: 0:01:17
 Epoch: 4, lr: 1.0e-02, train_loss: 1.6288, train_acc: 0.3797 test_loss: 1.3900, test_acc: 0.4500, best: 0.4500, time: 0:01:16
 Epoch: 5, lr: 1.0e-02, train_loss: 1.0509, train_acc: 0.5986 test_loss: 0.6850, test_acc: 0.7055, best: 0.7055, time: 0:01:14
 Epoch: 6, lr: 1.0e-02, train_loss: 0.5706, train_acc: 0.7680 test_loss: 0.6587, test_acc: 0.8450, best: 0.8450, time: 0:01:16
 Epoch: 7, lr: 1.0e-02, train_loss: 0.3365, train_acc: 0.8666 test_loss: 1.1179, test_acc: 0.8005, best: 0.8450, time: 0:01:15
 Epoch: 8, lr: 1.0e-02, train_loss: 0.1940, train_acc: 0.9275 test_loss: 0.0720, test_acc: 0.9910, best: 0.9910, time: 0:01:24
 Epoch: 9, lr: 1.0e-02, train_loss: 0.1341, train_acc: 0.9560 test_loss: 0.2794, test_acc: 0.8585, best: 0.9910, time: 0:01:21
 Epoch: 10, lr: 1.0e-02, train_loss: 0.0789, train_acc: 0.9754 test_loss: 0.4964, test_acc: 0.9000, best: 0.9910, time: 0:01:17
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0485, train_acc: 0.9846 test_loss: 0.1130, test_acc: 0.9520, best: 0.9910, time: 0:01:13
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0405, train_acc: 0.9881 test_loss: 0.7100, test_acc: 0.8295, best: 0.9910, time: 0:01:17
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0420, train_acc: 0.9862 test_loss: 0.2790, test_acc: 0.9500, best: 0.9910, time: 0:01:11
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0225, train_acc: 0.9933 test_loss: 0.4088, test_acc: 0.9230, best: 0.9910, time: 0:01:08
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0333, train_acc: 0.9894 test_loss: 0.0780, test_acc: 0.9620, best: 0.9910, time: 0:01:08
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0197, train_acc: 0.9943 test_loss: 0.0453, test_acc: 0.9755, best: 0.9910, time: 0:01:09
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0159, train_acc: 0.9949 test_loss: 0.4113, test_acc: 0.9250, best: 0.9910, time: 0:01:07
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0180, train_acc: 0.9953 test_loss: 0.3511, test_acc: 0.9500, best: 0.9910, time: 0:01:10
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0130, train_acc: 0.9959 test_loss: 0.8062, test_acc: 0.9000, best: 0.9910, time: 0:01:10
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0109, train_acc: 0.9967 test_loss: 0.7893, test_acc: 0.9000, best: 0.9910, time: 0:01:09
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0076, train_acc: 0.9973 test_loss: 0.4288, test_acc: 0.9275, best: 0.9910, time: 0:01:10
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0108, train_acc: 0.9971 test_loss: 0.3769, test_acc: 0.9500, best: 0.9910, time: 0:01:08
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0057, train_acc: 0.9981 test_loss: 0.2543, test_acc: 0.9500, best: 0.9910, time: 0:01:07
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0093, train_acc: 0.9976 test_loss: 0.5422, test_acc: 0.9275, best: 0.9910, time: 0:01:06
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0070, train_acc: 0.9982 test_loss: 0.3973, test_acc: 0.9285, best: 0.9910, time: 0:01:06
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0075, train_acc: 0.9976 test_loss: 0.4254, test_acc: 0.9445, best: 0.9910, time: 0:01:06
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0207, train_acc: 0.9947 test_loss: 0.6045, test_acc: 0.9215, best: 0.9910, time: 0:01:07
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0091, train_acc: 0.9976 test_loss: 0.5279, test_acc: 0.9220, best: 0.9910, time: 0:01:07
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0040, train_acc: 0.9990 test_loss: 0.2716, test_acc: 0.9500, best: 0.9910, time: 0:01:08
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0027, train_acc: 0.9990 test_loss: 0.6970, test_acc: 0.9210, best: 0.9910, time: 0:01:08
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0029, train_acc: 0.9994 test_loss: 0.6222, test_acc: 0.9230, best: 0.9910, time: 0:01:11
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9993 test_loss: 0.3800, test_acc: 0.9500, best: 0.9910, time: 0:01:12
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0012, train_acc: 0.9998 test_loss: 0.5181, test_acc: 0.9370, best: 0.9910, time: 0:01:10
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0013, train_acc: 0.9997 test_loss: 0.6175, test_acc: 0.9230, best: 0.9910, time: 0:01:12
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0014, train_acc: 0.9996 test_loss: 0.5182, test_acc: 0.9315, best: 0.9910, time: 0:01:10
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0022, train_acc: 0.9991 test_loss: 0.5955, test_acc: 0.9230, best: 0.9910, time: 0:01:09
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9997 test_loss: 0.4993, test_acc: 0.9345, best: 0.9910, time: 0:01:08
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.6112, test_acc: 0.9220, best: 0.9910, time: 0:01:07
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.5309, test_acc: 0.9270, best: 0.9910, time: 0:01:10
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0022, train_acc: 0.9994 test_loss: 0.5613, test_acc: 0.9250, best: 0.9910, time: 0:01:09
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.5718, test_acc: 0.9245, best: 0.9910, time: 0:01:10
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0014, train_acc: 0.9997 test_loss: 0.5724, test_acc: 0.9245, best: 0.9910, time: 0:01:12
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0018, train_acc: 0.9996 test_loss: 0.5709, test_acc: 0.9240, best: 0.9910, time: 0:01:12
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0016, train_acc: 0.9998 test_loss: 0.5633, test_acc: 0.9245, best: 0.9910, time: 0:01:16
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0016, train_acc: 0.9996 test_loss: 0.5659, test_acc: 0.9245, best: 0.9910, time: 0:01:23
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.5668, test_acc: 0.9245, best: 0.9910, time: 0:01:23
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0015, train_acc: 0.9997 test_loss: 0.5686, test_acc: 0.9245, best: 0.9910, time: 0:01:14
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9998 test_loss: 0.5701, test_acc: 0.9245, best: 0.9910, time: 0:01:12
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0013, train_acc: 0.9997 test_loss: 0.5719, test_acc: 0.9240, best: 0.9910, time: 0:01:12
 Highest accuracy: 0.9910