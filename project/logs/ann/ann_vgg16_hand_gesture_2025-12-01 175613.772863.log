
 Run on time: 2025-12-01 17:56:13.774795

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : HAND_GESTURE
	 batch_size           : 64
	 architecture         : VGG16
	 learning_rate        : 0.01
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 50
	 lr_interval          : 0.60 0.80 0.90
	 lr_reduce            : 10
	 optimizer            : SGD
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.3
	 kernel_size          : 3
	 devices              : 0
	 k_folds              : 10

Starting 10-Fold Cross Validation

---------------- FOLD 1/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3028, train_acc: 0.0974 test_loss: 2.3025, test_acc: 0.0990, best: 0.0990, time: 0:01:07
 Epoch: 2, lr: 1.0e-02, train_loss: 2.3024, train_acc: 0.1004 test_loss: 2.3020, test_acc: 0.0990, best: 0.0990, time: 0:01:05
 Epoch: 3, lr: 1.0e-02, train_loss: 2.3012, train_acc: 0.0985 test_loss: 2.2985, test_acc: 0.0990, best: 0.0990, time: 0:01:08
 Epoch: 4, lr: 1.0e-02, train_loss: 2.1390, train_acc: 0.1721 test_loss: 1.6405, test_acc: 0.3425, best: 0.3425, time: 0:01:13
 Epoch: 5, lr: 1.0e-02, train_loss: 1.4468, train_acc: 0.4521 test_loss: 1.1476, test_acc: 0.5840, best: 0.5840, time: 0:02:03
 Epoch: 6, lr: 1.0e-02, train_loss: 0.8711, train_acc: 0.6631 test_loss: 0.4719, test_acc: 0.8080, best: 0.8080, time: 0:01:54
 Epoch: 7, lr: 1.0e-02, train_loss: 0.4948, train_acc: 0.8052 test_loss: 0.2092, test_acc: 0.9350, best: 0.9350, time: 0:01:47
 Epoch: 8, lr: 1.0e-02, train_loss: 0.2978, train_acc: 0.8911 test_loss: 0.2275, test_acc: 0.9210, best: 0.9350, time: 0:01:38
 Epoch: 9, lr: 1.0e-02, train_loss: 0.1559, train_acc: 0.9486 test_loss: 0.0373, test_acc: 0.9900, best: 0.9900, time: 0:01:50
 Epoch: 10, lr: 1.0e-02, train_loss: 0.0818, train_acc: 0.9748 test_loss: 0.0227, test_acc: 0.9935, best: 0.9935, time: 0:01:47
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0661, train_acc: 0.9804 test_loss: 0.0183, test_acc: 0.9955, best: 0.9955, time: 0:01:45
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0487, train_acc: 0.9856 test_loss: 0.0161, test_acc: 0.9955, best: 0.9955, time: 0:01:38
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0329, train_acc: 0.9897 test_loss: 0.0186, test_acc: 0.9965, best: 0.9965, time: 0:01:45
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0356, train_acc: 0.9898 test_loss: 0.0047, test_acc: 0.9995, best: 0.9995, time: 0:01:45
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0241, train_acc: 0.9924 test_loss: 0.0054, test_acc: 0.9985, best: 0.9995, time: 0:01:40
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0232, train_acc: 0.9942 test_loss: 0.0033, test_acc: 0.9995, best: 0.9995, time: 0:01:37
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0211, train_acc: 0.9938 test_loss: 0.0030, test_acc: 0.9995, best: 0.9995, time: 0:01:39
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0108, train_acc: 0.9973 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:01:46
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0136, train_acc: 0.9965 test_loss: 0.0015, test_acc: 0.9995, best: 1.0000, time: 0:01:44
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0236, train_acc: 0.9924 test_loss: 0.0012, test_acc: 1.0000, best: 1.0000, time: 0:01:39
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0121, train_acc: 0.9961 test_loss: 0.0026, test_acc: 0.9995, best: 1.0000, time: 0:01:40
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0110, train_acc: 0.9972 test_loss: 0.0020, test_acc: 0.9995, best: 1.0000, time: 0:01:41
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0091, train_acc: 0.9973 test_loss: 0.0011, test_acc: 0.9995, best: 1.0000, time: 0:01:37
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0135, train_acc: 0.9961 test_loss: 0.0050, test_acc: 0.9995, best: 1.0000, time: 0:01:37
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0171, train_acc: 0.9955 test_loss: 0.0011, test_acc: 1.0000, best: 1.0000, time: 0:01:40
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0101, train_acc: 0.9973 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0073, train_acc: 0.9981 test_loss: 0.0011, test_acc: 0.9995, best: 1.0000, time: 0:01:40
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0163, train_acc: 0.9955 test_loss: 0.0083, test_acc: 0.9970, best: 1.0000, time: 0:01:37
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0070, train_acc: 0.9977 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0021, train_acc: 0.9993 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:31
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0012, train_acc: 0.9996 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0025, train_acc: 0.9993 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0015, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0019, train_acc: 0.9994 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:33
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9995 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:33
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0010, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0011, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0019, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:30
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0015, train_acc: 0.9994 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0016, train_acc: 0.9998 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0014, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0015, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0009, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:30
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0010, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0018, train_acc: 0.9995 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:32
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0009, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:30
 Fold 1 Best Accuracy: 1.0000

---------------- FOLD 2/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.2506, train_acc: 0.1032 test_loss: 2.0998, test_acc: 0.1190, best: 0.1190, time: 0:01:43
 Epoch: 2, lr: 1.0e-02, train_loss: 2.0117, train_acc: 0.1819 test_loss: 1.9784, test_acc: 0.2085, best: 0.2085, time: 0:02:14
 Epoch: 3, lr: 1.0e-02, train_loss: 1.7361, train_acc: 0.2878 test_loss: 1.0763, test_acc: 0.5485, best: 0.5485, time: 0:02:20
 Epoch: 4, lr: 1.0e-02, train_loss: 0.8557, train_acc: 0.6768 test_loss: 0.4918, test_acc: 0.8315, best: 0.8315, time: 0:01:55
 Epoch: 5, lr: 1.0e-02, train_loss: 0.4142, train_acc: 0.8535 test_loss: 0.1998, test_acc: 0.9515, best: 0.9515, time: 0:02:10
 Epoch: 6, lr: 1.0e-02, train_loss: 0.3050, train_acc: 0.8999 test_loss: 0.0710, test_acc: 0.9860, best: 0.9860, time: 0:01:58
 Epoch: 7, lr: 1.0e-02, train_loss: 0.1217, train_acc: 0.9586 test_loss: 0.0345, test_acc: 0.9880, best: 0.9880, time: 0:01:56
 Epoch: 8, lr: 1.0e-02, train_loss: 0.0914, train_acc: 0.9716 test_loss: 0.0632, test_acc: 0.9830, best: 0.9880, time: 0:01:47
 Epoch: 9, lr: 1.0e-02, train_loss: 0.0712, train_acc: 0.9783 test_loss: 0.0846, test_acc: 0.9765, best: 0.9880, time: 0:01:50
 Epoch: 10, lr: 1.0e-02, train_loss: 0.0468, train_acc: 0.9863 test_loss: 0.0156, test_acc: 0.9955, best: 0.9955, time: 0:02:04
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0428, train_acc: 0.9873 test_loss: 0.0290, test_acc: 0.9935, best: 0.9955, time: 0:01:54
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0324, train_acc: 0.9910 test_loss: 0.0094, test_acc: 0.9960, best: 0.9960, time: 0:01:55
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0204, train_acc: 0.9933 test_loss: 0.0094, test_acc: 0.9975, best: 0.9975, time: 0:01:25
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0242, train_acc: 0.9919 test_loss: 0.0101, test_acc: 0.9985, best: 0.9985, time: 0:01:31
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0167, train_acc: 0.9951 test_loss: 0.0136, test_acc: 0.9980, best: 0.9985, time: 0:01:36
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0191, train_acc: 0.9945 test_loss: 0.0104, test_acc: 0.9990, best: 0.9990, time: 0:01:38
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0235, train_acc: 0.9934 test_loss: 0.0062, test_acc: 0.9990, best: 0.9990, time: 0:01:26
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0115, train_acc: 0.9964 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:01:24
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0143, train_acc: 0.9963 test_loss: 0.0054, test_acc: 0.9980, best: 0.9990, time: 0:01:25
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0073, train_acc: 0.9982 test_loss: 0.0066, test_acc: 0.9990, best: 0.9990, time: 0:01:26
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0075, train_acc: 0.9983 test_loss: 0.0067, test_acc: 0.9985, best: 0.9990, time: 0:01:23
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0091, train_acc: 0.9972 test_loss: 0.0083, test_acc: 0.9990, best: 0.9990, time: 0:01:25
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0062, train_acc: 0.9987 test_loss: 0.0092, test_acc: 0.9990, best: 0.9990, time: 0:01:23
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0116, train_acc: 0.9976 test_loss: 0.0077, test_acc: 0.9990, best: 0.9990, time: 0:01:25
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0040, train_acc: 0.9988 test_loss: 0.0114, test_acc: 0.9990, best: 0.9990, time: 0:01:23
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0154, train_acc: 0.9961 test_loss: 0.0045, test_acc: 0.9990, best: 0.9990, time: 0:01:13
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0063, train_acc: 0.9982 test_loss: 0.0082, test_acc: 0.9990, best: 0.9990, time: 0:01:15
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0120, train_acc: 0.9966 test_loss: 0.0058, test_acc: 0.9985, best: 0.9990, time: 0:01:26
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0063, train_acc: 0.9982 test_loss: 0.0092, test_acc: 0.9985, best: 0.9990, time: 0:01:26
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0024, train_acc: 0.9993 test_loss: 0.0087, test_acc: 0.9990, best: 0.9990, time: 0:01:28
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0090, test_acc: 0.9990, best: 0.9990, time: 0:01:30
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0013, train_acc: 0.9996 test_loss: 0.0091, test_acc: 0.9990, best: 0.9990, time: 0:01:29
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0019, train_acc: 0.9996 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:01:28
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0008, train_acc: 0.9998 test_loss: 0.0091, test_acc: 0.9990, best: 0.9990, time: 0:01:28
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0018, train_acc: 0.9997 test_loss: 0.0075, test_acc: 0.9990, best: 0.9990, time: 0:01:29
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0018, train_acc: 0.9997 test_loss: 0.0073, test_acc: 0.9990, best: 0.9990, time: 0:01:33
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0018, train_acc: 0.9997 test_loss: 0.0073, test_acc: 0.9990, best: 0.9990, time: 0:01:29
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0009, train_acc: 0.9998 test_loss: 0.0070, test_acc: 0.9990, best: 0.9990, time: 0:01:26
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:01:25
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0010, train_acc: 0.9997 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:01:24
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0012, train_acc: 0.9998 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:01:24
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0006, train_acc: 0.9998 test_loss: 0.0077, test_acc: 0.9990, best: 0.9990, time: 0:01:23
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0010, train_acc: 0.9998 test_loss: 0.0077, test_acc: 0.9990, best: 0.9990, time: 0:01:10
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0008, train_acc: 0.9997 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:00:58
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0009, train_acc: 0.9997 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:00:58
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0008, train_acc: 0.9999 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:00:58
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0007, train_acc: 0.9999 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:00:58
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0008, train_acc: 0.9997 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:01:01
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0010, train_acc: 0.9998 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:00:59
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9996 test_loss: 0.0079, test_acc: 0.9990, best: 0.9990, time: 0:00:58
 Fold 2 Best Accuracy: 0.9990

---------------- FOLD 3/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3028, train_acc: 0.0968 test_loss: 2.3026, test_acc: 0.1085, best: 0.1085, time: 0:01:01
 Epoch: 2, lr: 1.0e-02, train_loss: 2.3024, train_acc: 0.1025 test_loss: 2.3022, test_acc: 0.1080, best: 0.1085, time: 0:00:58
 Epoch: 3, lr: 1.0e-02, train_loss: 2.3018, train_acc: 0.0974 test_loss: 2.2998, test_acc: 0.1080, best: 0.1085, time: 0:00:58
 Epoch: 4, lr: 1.0e-02, train_loss: 2.2974, train_acc: 0.1011 test_loss: 2.2579, test_acc: 0.2080, best: 0.2080, time: 0:01:01
 Epoch: 5, lr: 1.0e-02, train_loss: 1.7352, train_acc: 0.3486 test_loss: 1.5901, test_acc: 0.4615, best: 0.4615, time: 0:01:01
 Epoch: 6, lr: 1.0e-02, train_loss: 1.1403, train_acc: 0.5581 test_loss: 0.6292, test_acc: 0.7355, best: 0.7355, time: 0:01:29
 Epoch: 7, lr: 1.0e-02, train_loss: 0.5880, train_acc: 0.7703 test_loss: 0.3968, test_acc: 0.8285, best: 0.8285, time: 0:01:52
 Epoch: 8, lr: 1.0e-02, train_loss: 0.3582, train_acc: 0.8644 test_loss: 0.1091, test_acc: 0.9495, best: 0.9495, time: 0:01:52
 Epoch: 9, lr: 1.0e-02, train_loss: 0.2151, train_acc: 0.9233 test_loss: 0.1077, test_acc: 0.9675, best: 0.9675, time: 0:01:50
 Epoch: 10, lr: 1.0e-02, train_loss: 0.1208, train_acc: 0.9586 test_loss: 0.0306, test_acc: 0.9920, best: 0.9920, time: 0:01:47
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0777, train_acc: 0.9753 test_loss: 0.0068, test_acc: 0.9975, best: 0.9975, time: 0:01:47
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0585, train_acc: 0.9825 test_loss: 0.0125, test_acc: 0.9955, best: 0.9975, time: 0:01:41
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0397, train_acc: 0.9878 test_loss: 0.0031, test_acc: 0.9990, best: 0.9990, time: 0:01:47
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0363, train_acc: 0.9895 test_loss: 0.0033, test_acc: 0.9980, best: 0.9990, time: 0:01:41
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0246, train_acc: 0.9929 test_loss: 0.0006, test_acc: 1.0000, best: 1.0000, time: 0:01:50
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0214, train_acc: 0.9934 test_loss: 0.0019, test_acc: 0.9995, best: 1.0000, time: 0:01:38
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0335, train_acc: 0.9906 test_loss: 0.0090, test_acc: 0.9985, best: 1.0000, time: 0:01:38
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0320, train_acc: 0.9903 test_loss: 0.0021, test_acc: 0.9990, best: 1.0000, time: 0:01:38
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0181, train_acc: 0.9951 test_loss: 0.0041, test_acc: 0.9990, best: 1.0000, time: 0:01:38
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0122, train_acc: 0.9967 test_loss: 0.0004, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0140, train_acc: 0.9964 test_loss: 0.0014, test_acc: 1.0000, best: 1.0000, time: 0:01:39
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0112, train_acc: 0.9971 test_loss: 0.0749, test_acc: 0.9715, best: 1.0000, time: 0:01:38
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0146, train_acc: 0.9966 test_loss: 0.0015, test_acc: 0.9990, best: 1.0000, time: 0:01:39
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0123, train_acc: 0.9968 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0100, train_acc: 0.9976 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:39
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0123, train_acc: 0.9963 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:39
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0090, train_acc: 0.9976 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0083, train_acc: 0.9979 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0075, train_acc: 0.9979 test_loss: 0.0011, test_acc: 0.9995, best: 1.0000, time: 0:01:38
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0030, train_acc: 0.9991 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0017, train_acc: 0.9994 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0021, train_acc: 0.9993 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9995 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0014, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0010, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0009, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:39
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0012, train_acc: 0.9998 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:31
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0007, train_acc: 0.9998 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0017, train_acc: 0.9994 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0016, train_acc: 0.9995 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0015, train_acc: 0.9994 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0018, train_acc: 0.9995 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0013, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0014, train_acc: 0.9998 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0014, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0017, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Fold 3 Best Accuracy: 1.0000

---------------- FOLD 4/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3028, train_acc: 0.0970 test_loss: 2.3025, test_acc: 0.1030, best: 0.1030, time: 0:01:44
 Epoch: 2, lr: 1.0e-02, train_loss: 2.3021, train_acc: 0.0978 test_loss: 2.3017, test_acc: 0.0980, best: 0.1030, time: 0:01:37
 Epoch: 3, lr: 1.0e-02, train_loss: 2.2988, train_acc: 0.1016 test_loss: 2.2808, test_acc: 0.0980, best: 0.1030, time: 0:01:36
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8540, train_acc: 0.2989 test_loss: 1.5490, test_acc: 0.4300, best: 0.4300, time: 0:01:46
 Epoch: 5, lr: 1.0e-02, train_loss: 1.2621, train_acc: 0.5197 test_loss: 1.1454, test_acc: 0.5685, best: 0.5685, time: 0:01:46
 Epoch: 6, lr: 1.0e-02, train_loss: 0.7035, train_acc: 0.7291 test_loss: 0.4763, test_acc: 0.8480, best: 0.8480, time: 0:01:46
 Epoch: 7, lr: 1.0e-02, train_loss: 0.3975, train_acc: 0.8498 test_loss: 0.1715, test_acc: 0.9365, best: 0.9365, time: 0:01:47
 Epoch: 8, lr: 1.0e-02, train_loss: 0.2455, train_acc: 0.9111 test_loss: 0.1478, test_acc: 0.9535, best: 0.9535, time: 0:01:48
 Epoch: 9, lr: 1.0e-02, train_loss: 0.1438, train_acc: 0.9516 test_loss: 0.0597, test_acc: 0.9780, best: 0.9780, time: 0:01:47
 Epoch: 10, lr: 1.0e-02, train_loss: 0.0823, train_acc: 0.9738 test_loss: 0.0719, test_acc: 0.9780, best: 0.9780, time: 0:01:38
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0678, train_acc: 0.9796 test_loss: 0.0348, test_acc: 0.9880, best: 0.9880, time: 0:01:46
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0431, train_acc: 0.9861 test_loss: 0.0173, test_acc: 0.9935, best: 0.9935, time: 0:01:47
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0353, train_acc: 0.9883 test_loss: 0.0310, test_acc: 0.9880, best: 0.9935, time: 0:01:38
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0298, train_acc: 0.9907 test_loss: 0.0082, test_acc: 0.9975, best: 0.9975, time: 0:01:45
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0247, train_acc: 0.9926 test_loss: 0.0040, test_acc: 0.9990, best: 0.9990, time: 0:01:47
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0203, train_acc: 0.9940 test_loss: 0.0072, test_acc: 0.9985, best: 0.9990, time: 0:01:37
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0317, train_acc: 0.9903 test_loss: 0.0077, test_acc: 0.9985, best: 0.9990, time: 0:01:38
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0141, train_acc: 0.9962 test_loss: 0.0032, test_acc: 0.9990, best: 0.9990, time: 0:01:38
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0162, train_acc: 0.9951 test_loss: 0.0090, test_acc: 0.9955, best: 0.9990, time: 0:01:38
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0087, train_acc: 0.9973 test_loss: 0.0007, test_acc: 1.0000, best: 1.0000, time: 0:01:46
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0165, train_acc: 0.9957 test_loss: 0.0010, test_acc: 0.9995, best: 1.0000, time: 0:01:36
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0084, train_acc: 0.9980 test_loss: 0.0014, test_acc: 0.9995, best: 1.0000, time: 0:01:35
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0083, train_acc: 0.9976 test_loss: 0.0036, test_acc: 0.9995, best: 1.0000, time: 0:01:36
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0180, train_acc: 0.9952 test_loss: 0.0014, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0088, train_acc: 0.9974 test_loss: 0.0007, test_acc: 1.0000, best: 1.0000, time: 0:01:35
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0092, train_acc: 0.9979 test_loss: 0.0014, test_acc: 0.9990, best: 1.0000, time: 0:01:36
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0083, train_acc: 0.9978 test_loss: 0.0027, test_acc: 0.9995, best: 1.0000, time: 0:01:36
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0122, train_acc: 0.9966 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:01:35
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0093, train_acc: 0.9974 test_loss: 0.0021, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0041, train_acc: 0.9992 test_loss: 0.0004, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0027, train_acc: 0.9993 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0014, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:39
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9996 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0018, train_acc: 0.9994 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9998 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:39
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0013, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0009, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0015, train_acc: 0.9995 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0019, train_acc: 0.9995 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:31
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0024, train_acc: 0.9994 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0014, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0011, train_acc: 0.9998 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9998 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0020, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:35
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0014, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0016, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:01:35
 Fold 4 Best Accuracy: 1.0000

---------------- FOLD 5/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3028, train_acc: 0.0969 test_loss: 2.3025, test_acc: 0.1010, best: 0.1010, time: 0:01:44
 Epoch: 2, lr: 1.0e-02, train_loss: 2.3026, train_acc: 0.0990 test_loss: 2.3025, test_acc: 0.0970, best: 0.1010, time: 0:01:36
 Epoch: 3, lr: 1.0e-02, train_loss: 2.2900, train_acc: 0.1003 test_loss: 2.2217, test_acc: 0.1020, best: 0.1020, time: 0:01:44
 Epoch: 4, lr: 1.0e-02, train_loss: 2.0767, train_acc: 0.1561 test_loss: 1.9942, test_acc: 0.1760, best: 0.1760, time: 0:01:44
 Epoch: 5, lr: 1.0e-02, train_loss: 1.8394, train_acc: 0.2436 test_loss: 1.3310, test_acc: 0.4455, best: 0.4455, time: 0:01:47
 Epoch: 6, lr: 1.0e-02, train_loss: 1.9026, train_acc: 0.2624 test_loss: 1.6418, test_acc: 0.3600, best: 0.4455, time: 0:01:34
 Epoch: 7, lr: 1.0e-02, train_loss: 1.2780, train_acc: 0.5229 test_loss: 0.7344, test_acc: 0.7110, best: 0.7110, time: 0:01:45
 Epoch: 8, lr: 1.0e-02, train_loss: 0.6721, train_acc: 0.7367 test_loss: 0.7751, test_acc: 0.7560, best: 0.7560, time: 0:01:44
 Epoch: 9, lr: 1.0e-02, train_loss: 0.4154, train_acc: 0.8424 test_loss: 0.1442, test_acc: 0.9410, best: 0.9410, time: 0:01:45
 Epoch: 10, lr: 1.0e-02, train_loss: 0.2283, train_acc: 0.9178 test_loss: 0.0577, test_acc: 0.9870, best: 0.9870, time: 0:01:44
 Epoch: 11, lr: 1.0e-02, train_loss: 0.1491, train_acc: 0.9503 test_loss: 0.0239, test_acc: 0.9940, best: 0.9940, time: 0:01:44
 Epoch: 12, lr: 1.0e-02, train_loss: 0.1072, train_acc: 0.9661 test_loss: 0.0471, test_acc: 0.9790, best: 0.9940, time: 0:01:36
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0813, train_acc: 0.9748 test_loss: 0.1010, test_acc: 0.9695, best: 0.9940, time: 0:01:36
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0378, train_acc: 0.9882 test_loss: 0.0116, test_acc: 0.9950, best: 0.9950, time: 0:01:44
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0399, train_acc: 0.9881 test_loss: 0.0086, test_acc: 0.9970, best: 0.9970, time: 0:01:44
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0355, train_acc: 0.9879 test_loss: 0.0206, test_acc: 0.9975, best: 0.9975, time: 0:01:44
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0219, train_acc: 0.9944 test_loss: 0.0014, test_acc: 1.0000, best: 1.0000, time: 0:01:44
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0213, train_acc: 0.9937 test_loss: 0.0035, test_acc: 0.9995, best: 1.0000, time: 0:01:36
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0244, train_acc: 0.9928 test_loss: 0.0036, test_acc: 0.9995, best: 1.0000, time: 0:01:36
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0259, train_acc: 0.9929 test_loss: 0.0015, test_acc: 0.9995, best: 1.0000, time: 0:01:36
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0214, train_acc: 0.9934 test_loss: 0.0044, test_acc: 0.9995, best: 1.0000, time: 0:01:35
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0131, train_acc: 0.9963 test_loss: 0.0011, test_acc: 0.9995, best: 1.0000, time: 0:01:36
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0122, train_acc: 0.9970 test_loss: 0.0021, test_acc: 0.9990, best: 1.0000, time: 0:01:36
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0137, train_acc: 0.9963 test_loss: 0.0018, test_acc: 0.9995, best: 1.0000, time: 0:01:35
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0129, train_acc: 0.9966 test_loss: 0.0010, test_acc: 0.9995, best: 1.0000, time: 0:01:36
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0099, train_acc: 0.9973 test_loss: 0.0015, test_acc: 0.9990, best: 1.0000, time: 0:01:37
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0082, train_acc: 0.9980 test_loss: 0.0010, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0166, train_acc: 0.9954 test_loss: 0.0008, test_acc: 1.0000, best: 1.0000, time: 0:01:35
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0294, train_acc: 0.9914 test_loss: 0.0136, test_acc: 0.9980, best: 1.0000, time: 0:01:37
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0155, train_acc: 0.9958 test_loss: 0.0007, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0086, train_acc: 0.9977 test_loss: 0.0005, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0057, train_acc: 0.9985 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0056, train_acc: 0.9985 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0052, train_acc: 0.9987 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0047, train_acc: 0.9989 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0028, train_acc: 0.9992 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0047, train_acc: 0.9988 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:39
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0031, train_acc: 0.9992 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0055, train_acc: 0.9987 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0038, train_acc: 0.9991 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0040, train_acc: 0.9988 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0039, train_acc: 0.9989 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0046, train_acc: 0.9989 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0038, train_acc: 0.9989 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:37
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0031, train_acc: 0.9992 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0030, train_acc: 0.9992 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:38
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0037, train_acc: 0.9991 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:35
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0035, train_acc: 0.9993 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0037, train_acc: 0.9991 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:36
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0041, train_acc: 0.9989 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:35
 Fold 5 Best Accuracy: 1.0000

---------------- FOLD 6/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.2963, train_acc: 0.0994 test_loss: 2.2648, test_acc: 0.0960, best: 0.0960, time: 0:01:50
 Epoch: 2, lr: 1.0e-02, train_loss: 2.1124, train_acc: 0.1473 test_loss: 1.9286, test_acc: 0.1975, best: 0.1975, time: 0:01:50
 Epoch: 3, lr: 1.0e-02, train_loss: 2.0030, train_acc: 0.1779 test_loss: 2.2979, test_acc: 0.0925, best: 0.1975, time: 0:01:42
 Epoch: 4, lr: 1.0e-02, train_loss: 1.5155, train_acc: 0.3802 test_loss: 0.9670, test_acc: 0.6570, best: 0.6570, time: 0:01:51
 Epoch: 5, lr: 1.0e-02, train_loss: 0.8345, train_acc: 0.6763 test_loss: 0.4719, test_acc: 0.8320, best: 0.8320, time: 0:01:52
 Epoch: 6, lr: 1.0e-02, train_loss: 0.4335, train_acc: 0.8387 test_loss: 0.1907, test_acc: 0.9325, best: 0.9325, time: 0:01:51
 Epoch: 7, lr: 1.0e-02, train_loss: 0.2386, train_acc: 0.9144 test_loss: 0.0868, test_acc: 0.9795, best: 0.9795, time: 0:01:51
 Epoch: 8, lr: 1.0e-02, train_loss: 0.1403, train_acc: 0.9527 test_loss: 0.0642, test_acc: 0.9830, best: 0.9830, time: 0:01:53
 Epoch: 9, lr: 1.0e-02, train_loss: 0.0860, train_acc: 0.9711 test_loss: 0.0223, test_acc: 0.9920, best: 0.9920, time: 0:01:51
 Epoch: 10, lr: 1.0e-02, train_loss: 0.0639, train_acc: 0.9792 test_loss: 0.0259, test_acc: 0.9910, best: 0.9920, time: 0:01:41
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0450, train_acc: 0.9859 test_loss: 0.0140, test_acc: 0.9950, best: 0.9950, time: 0:01:49
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0401, train_acc: 0.9881 test_loss: 0.0125, test_acc: 0.9960, best: 0.9960, time: 0:01:50
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0389, train_acc: 0.9882 test_loss: 0.0142, test_acc: 0.9970, best: 0.9970, time: 0:01:50
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0355, train_acc: 0.9892 test_loss: 0.0136, test_acc: 0.9975, best: 0.9975, time: 0:01:49
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0266, train_acc: 0.9922 test_loss: 0.0157, test_acc: 0.9955, best: 0.9975, time: 0:01:45
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0187, train_acc: 0.9947 test_loss: 0.0076, test_acc: 0.9975, best: 0.9975, time: 0:01:44
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0235, train_acc: 0.9943 test_loss: 0.0070, test_acc: 0.9975, best: 0.9975, time: 0:01:41
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0193, train_acc: 0.9947 test_loss: 0.0075, test_acc: 0.9980, best: 0.9980, time: 0:01:51
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0165, train_acc: 0.9956 test_loss: 0.0040, test_acc: 0.9980, best: 0.9980, time: 0:01:32
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0211, train_acc: 0.9948 test_loss: 0.0063, test_acc: 0.9980, best: 0.9980, time: 0:02:18
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0241, train_acc: 0.9928 test_loss: 0.0047, test_acc: 0.9985, best: 0.9985, time: 0:01:53
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0235, train_acc: 0.9931 test_loss: 0.0047, test_acc: 0.9985, best: 0.9985, time: 0:01:41
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0116, train_acc: 0.9975 test_loss: 0.0018, test_acc: 1.0000, best: 1.0000, time: 0:01:52
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0109, train_acc: 0.9976 test_loss: 0.0008, test_acc: 1.0000, best: 1.0000, time: 0:01:43
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0089, train_acc: 0.9976 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0087, train_acc: 0.9980 test_loss: 0.0023, test_acc: 0.9995, best: 1.0000, time: 0:01:43
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0137, train_acc: 0.9961 test_loss: 0.0048, test_acc: 0.9995, best: 1.0000, time: 0:01:42
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0106, train_acc: 0.9969 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0061, train_acc: 0.9984 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0041, train_acc: 0.9991 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0013, train_acc: 0.9997 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:44
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0013, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0011, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0013, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9994 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0010, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0013, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0009, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0007, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0009, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0015, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:43
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0010, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0021, train_acc: 0.9996 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0013, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0017, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0007, train_acc: 0.9999 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0014, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:42
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0016, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:41
 Fold 6 Best Accuracy: 1.0000

---------------- FOLD 7/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3029, train_acc: 0.0974 test_loss: 2.3025, test_acc: 0.1405, best: 0.1405, time: 0:02:02
 Epoch: 2, lr: 1.0e-02, train_loss: 2.3026, train_acc: 0.1008 test_loss: 2.3025, test_acc: 0.0940, best: 0.1405, time: 0:01:51
 Epoch: 3, lr: 1.0e-02, train_loss: 2.2795, train_acc: 0.1029 test_loss: 2.1748, test_acc: 0.0940, best: 0.1405, time: 0:01:52
 Epoch: 4, lr: 1.0e-02, train_loss: 2.0640, train_acc: 0.1608 test_loss: 1.9253, test_acc: 0.2165, best: 0.2165, time: 0:02:01
 Epoch: 5, lr: 1.0e-02, train_loss: 1.9158, train_acc: 0.2137 test_loss: 1.7828, test_acc: 0.2600, best: 0.2600, time: 0:01:59
 Epoch: 6, lr: 1.0e-02, train_loss: 1.2642, train_acc: 0.4951 test_loss: 0.6401, test_acc: 0.7255, best: 0.7255, time: 0:02:00
 Epoch: 7, lr: 1.0e-02, train_loss: 0.6638, train_acc: 0.7449 test_loss: 0.4260, test_acc: 0.8430, best: 0.8430, time: 0:02:00
 Epoch: 8, lr: 1.0e-02, train_loss: 0.3515, train_acc: 0.8748 test_loss: 0.1681, test_acc: 0.9335, best: 0.9335, time: 0:02:00
 Epoch: 9, lr: 1.0e-02, train_loss: 0.1869, train_acc: 0.9366 test_loss: 0.1085, test_acc: 0.9750, best: 0.9750, time: 0:02:00
 Epoch: 10, lr: 1.0e-02, train_loss: 0.1289, train_acc: 0.9566 test_loss: 0.0572, test_acc: 0.9795, best: 0.9795, time: 0:02:00
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0833, train_acc: 0.9722 test_loss: 0.0212, test_acc: 0.9945, best: 0.9945, time: 0:01:59
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0562, train_acc: 0.9833 test_loss: 0.0130, test_acc: 0.9960, best: 0.9960, time: 0:01:59
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0485, train_acc: 0.9849 test_loss: 0.0101, test_acc: 0.9980, best: 0.9980, time: 0:02:00
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0309, train_acc: 0.9904 test_loss: 0.0051, test_acc: 0.9990, best: 0.9990, time: 0:01:59
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0287, train_acc: 0.9914 test_loss: 0.0019, test_acc: 1.0000, best: 1.0000, time: 0:01:59
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0281, train_acc: 0.9921 test_loss: 0.0027, test_acc: 0.9995, best: 1.0000, time: 0:01:49
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0302, train_acc: 0.9921 test_loss: 0.0085, test_acc: 0.9980, best: 1.0000, time: 0:01:50
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0154, train_acc: 0.9957 test_loss: 0.0025, test_acc: 0.9990, best: 1.0000, time: 0:01:49
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0150, train_acc: 0.9954 test_loss: 0.0013, test_acc: 0.9995, best: 1.0000, time: 0:01:48
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0084, train_acc: 0.9978 test_loss: 0.0010, test_acc: 0.9995, best: 1.0000, time: 0:01:49
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0104, train_acc: 0.9974 test_loss: 0.0010, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0115, train_acc: 0.9969 test_loss: 0.0009, test_acc: 0.9995, best: 1.0000, time: 0:01:50
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0093, train_acc: 0.9977 test_loss: 0.0024, test_acc: 0.9990, best: 1.0000, time: 0:01:49
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0145, train_acc: 0.9953 test_loss: 0.0005, test_acc: 1.0000, best: 1.0000, time: 0:01:48
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0115, train_acc: 0.9967 test_loss: 0.0043, test_acc: 0.9990, best: 1.0000, time: 0:01:49
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0161, train_acc: 0.9962 test_loss: 0.0021, test_acc: 0.9990, best: 1.0000, time: 0:01:50
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0069, train_acc: 0.9982 test_loss: 0.0004, test_acc: 1.0000, best: 1.0000, time: 0:01:48
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0060, train_acc: 0.9982 test_loss: 0.0089, test_acc: 0.9975, best: 1.0000, time: 0:01:49
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0076, train_acc: 0.9978 test_loss: 0.0032, test_acc: 0.9990, best: 1.0000, time: 0:01:49
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0030, train_acc: 0.9995 test_loss: 0.0023, test_acc: 0.9995, best: 1.0000, time: 0:01:51
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9997 test_loss: 0.0008, test_acc: 0.9995, best: 1.0000, time: 0:01:55
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0017, train_acc: 0.9996 test_loss: 0.0012, test_acc: 0.9995, best: 1.0000, time: 0:01:49
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9996 test_loss: 0.0007, test_acc: 0.9995, best: 1.0000, time: 0:01:49
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0009, train_acc: 0.9998 test_loss: 0.0005, test_acc: 0.9995, best: 1.0000, time: 0:01:49
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0021, train_acc: 0.9997 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:50
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9995 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0015, train_acc: 0.9994 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0011, train_acc: 0.9998 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0008, train_acc: 0.9998 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0015, train_acc: 0.9998 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:50
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0021, train_acc: 0.9995 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0022, train_acc: 0.9996 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0009, train_acc: 0.9998 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0017, train_acc: 0.9997 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:50
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0009, train_acc: 0.9997 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:52
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9998 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:49
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0017, train_acc: 0.9998 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:51
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0020, train_acc: 0.9996 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:01:50
 Fold 7 Best Accuracy: 1.0000

---------------- FOLD 8/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.2524, train_acc: 0.1034 test_loss: 2.0909, test_acc: 0.1555, best: 0.1555, time: 0:02:06
 Epoch: 2, lr: 1.0e-02, train_loss: 2.0098, train_acc: 0.1889 test_loss: 1.9827, test_acc: 0.2035, best: 0.2035, time: 0:02:06
 Epoch: 3, lr: 1.0e-02, train_loss: 1.7326, train_acc: 0.2787 test_loss: 1.2798, test_acc: 0.4625, best: 0.4625, time: 0:02:06
 Epoch: 4, lr: 1.0e-02, train_loss: 0.9887, train_acc: 0.5980 test_loss: 0.5066, test_acc: 0.8110, best: 0.8110, time: 0:02:06
 Epoch: 5, lr: 1.0e-02, train_loss: 0.4842, train_acc: 0.8184 test_loss: 0.3987, test_acc: 0.8990, best: 0.8990, time: 0:02:06
 Epoch: 6, lr: 1.0e-02, train_loss: 0.2325, train_acc: 0.9209 test_loss: 0.1805, test_acc: 0.9285, best: 0.9285, time: 0:02:08
 Epoch: 7, lr: 1.0e-02, train_loss: 0.1337, train_acc: 0.9564 test_loss: 0.0451, test_acc: 0.9825, best: 0.9825, time: 0:02:05
 Epoch: 8, lr: 1.0e-02, train_loss: 0.0842, train_acc: 0.9749 test_loss: 0.0360, test_acc: 0.9920, best: 0.9920, time: 0:02:06
 Epoch: 9, lr: 1.0e-02, train_loss: 0.0694, train_acc: 0.9775 test_loss: 0.0163, test_acc: 0.9960, best: 0.9960, time: 0:02:06
 Epoch: 10, lr: 1.0e-02, train_loss: 0.0462, train_acc: 0.9858 test_loss: 0.0150, test_acc: 0.9970, best: 0.9970, time: 0:02:05
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0525, train_acc: 0.9845 test_loss: 0.0167, test_acc: 0.9960, best: 0.9970, time: 0:01:55
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0487, train_acc: 0.9853 test_loss: 0.0118, test_acc: 0.9960, best: 0.9970, time: 0:02:01
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0278, train_acc: 0.9923 test_loss: 0.0090, test_acc: 0.9975, best: 0.9975, time: 0:02:05
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0344, train_acc: 0.9903 test_loss: 0.0180, test_acc: 0.9965, best: 0.9975, time: 0:01:55
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0304, train_acc: 0.9918 test_loss: 0.0108, test_acc: 0.9970, best: 0.9975, time: 0:01:55
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0187, train_acc: 0.9940 test_loss: 0.0094, test_acc: 0.9985, best: 0.9985, time: 0:02:05
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0131, train_acc: 0.9965 test_loss: 0.0022, test_acc: 0.9990, best: 0.9990, time: 0:02:05
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0117, train_acc: 0.9972 test_loss: 0.0044, test_acc: 0.9990, best: 0.9990, time: 0:01:56
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0162, train_acc: 0.9953 test_loss: 0.0032, test_acc: 0.9985, best: 0.9990, time: 0:01:54
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0176, train_acc: 0.9947 test_loss: 0.0035, test_acc: 0.9990, best: 0.9990, time: 0:01:54
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0080, train_acc: 0.9973 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:02:05
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0154, train_acc: 0.9960 test_loss: 0.0055, test_acc: 0.9990, best: 0.9995, time: 0:01:54
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0094, train_acc: 0.9974 test_loss: 0.0049, test_acc: 0.9990, best: 0.9995, time: 0:01:54
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0067, train_acc: 0.9982 test_loss: 0.0060, test_acc: 0.9990, best: 0.9995, time: 0:01:54
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0062, train_acc: 0.9981 test_loss: 0.0025, test_acc: 0.9990, best: 0.9995, time: 0:01:54
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0188, train_acc: 0.9948 test_loss: 0.0036, test_acc: 0.9990, best: 0.9995, time: 0:01:55
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0092, train_acc: 0.9972 test_loss: 0.0041, test_acc: 0.9990, best: 0.9995, time: 0:01:54
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0076, train_acc: 0.9981 test_loss: 0.0035, test_acc: 0.9985, best: 0.9995, time: 0:01:55
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0064, train_acc: 0.9979 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0032, train_acc: 0.9993 test_loss: 0.0007, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0017, train_acc: 0.9994 test_loss: 0.0009, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0011, train_acc: 0.9998 test_loss: 0.0018, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0009, train_acc: 0.9997 test_loss: 0.0015, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0008, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0008, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0020, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0016, train_acc: 0.9996 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0013, train_acc: 0.9998 test_loss: 0.0009, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.0010, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0010, train_acc: 0.9997 test_loss: 0.0011, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0014, train_acc: 0.9996 test_loss: 0.0011, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0009, train_acc: 0.9997 test_loss: 0.0012, test_acc: 0.9995, best: 0.9995, time: 0:02:04
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0010, train_acc: 0.9998 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0013, train_acc: 0.9996 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:56
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0006, train_acc: 0.9998 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:55
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0010, train_acc: 0.9998 test_loss: 0.0013, test_acc: 0.9995, best: 0.9995, time: 0:01:54
 Fold 8 Best Accuracy: 0.9995

---------------- FOLD 9/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3028, train_acc: 0.0988 test_loss: 2.3028, test_acc: 0.0875, best: 0.0875, time: 0:02:19
 Epoch: 2, lr: 1.0e-02, train_loss: 2.3024, train_acc: 0.1003 test_loss: 2.3028, test_acc: 0.0885, best: 0.0885, time: 0:02:15
 Epoch: 3, lr: 1.0e-02, train_loss: 2.3018, train_acc: 0.1011 test_loss: 2.3016, test_acc: 0.0885, best: 0.0885, time: 0:02:06
 Epoch: 4, lr: 1.0e-02, train_loss: 2.2911, train_acc: 0.1061 test_loss: 2.1411, test_acc: 0.2085, best: 0.2085, time: 0:02:18
 Epoch: 5, lr: 1.0e-02, train_loss: 1.6872, train_acc: 0.3691 test_loss: 1.2977, test_acc: 0.5155, best: 0.5155, time: 0:02:18
 Epoch: 6, lr: 1.0e-02, train_loss: 1.0997, train_acc: 0.5786 test_loss: 0.7015, test_acc: 0.7350, best: 0.7350, time: 0:02:18
 Epoch: 7, lr: 1.0e-02, train_loss: 0.5832, train_acc: 0.7745 test_loss: 0.2794, test_acc: 0.9070, best: 0.9070, time: 0:02:18
 Epoch: 8, lr: 1.0e-02, train_loss: 0.3334, train_acc: 0.8755 test_loss: 0.1009, test_acc: 0.9760, best: 0.9760, time: 0:02:14
 Epoch: 9, lr: 1.0e-02, train_loss: 0.1871, train_acc: 0.9382 test_loss: 0.0785, test_acc: 0.9695, best: 0.9760, time: 0:02:02
 Epoch: 10, lr: 1.0e-02, train_loss: 0.1018, train_acc: 0.9676 test_loss: 0.0390, test_acc: 0.9910, best: 0.9910, time: 0:02:18
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0873, train_acc: 0.9734 test_loss: 0.0114, test_acc: 0.9965, best: 0.9965, time: 0:02:18
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0472, train_acc: 0.9854 test_loss: 0.0137, test_acc: 0.9950, best: 0.9965, time: 0:02:06
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0414, train_acc: 0.9870 test_loss: 0.0143, test_acc: 0.9960, best: 0.9965, time: 0:02:06
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0270, train_acc: 0.9926 test_loss: 0.0071, test_acc: 0.9985, best: 0.9985, time: 0:02:17
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0192, train_acc: 0.9940 test_loss: 0.0012, test_acc: 1.0000, best: 1.0000, time: 0:02:18
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0172, train_acc: 0.9956 test_loss: 0.0032, test_acc: 0.9995, best: 1.0000, time: 0:02:07
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0203, train_acc: 0.9946 test_loss: 0.0060, test_acc: 0.9990, best: 1.0000, time: 0:02:06
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0168, train_acc: 0.9952 test_loss: 0.0006, test_acc: 1.0000, best: 1.0000, time: 0:02:05
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0182, train_acc: 0.9952 test_loss: 0.0004, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0133, train_acc: 0.9959 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0149, train_acc: 0.9961 test_loss: 0.0009, test_acc: 1.0000, best: 1.0000, time: 0:02:05
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0131, train_acc: 0.9959 test_loss: 0.0024, test_acc: 0.9995, best: 1.0000, time: 0:02:06
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0151, train_acc: 0.9949 test_loss: 0.0009, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0136, train_acc: 0.9958 test_loss: 0.0023, test_acc: 0.9995, best: 1.0000, time: 0:02:05
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0093, train_acc: 0.9975 test_loss: 0.0004, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0120, train_acc: 0.9967 test_loss: 0.0005, test_acc: 1.0000, best: 1.0000, time: 0:02:02
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0076, train_acc: 0.9982 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:02:05
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0064, train_acc: 0.9982 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0077, train_acc: 0.9981 test_loss: 0.0006, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0035, train_acc: 0.9992 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:02:05
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9994 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0021, train_acc: 0.9995 test_loss: 0.0002, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9995 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:05
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0018, train_acc: 0.9994 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0025, train_acc: 0.9992 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:13
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0017, train_acc: 0.9994 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:10
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9996 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0025, train_acc: 0.9993 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:07
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0013, train_acc: 0.9996 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:02:07
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0014, train_acc: 0.9997 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:07
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0015, train_acc: 0.9998 test_loss: 0.0000, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0017, train_acc: 0.9994 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0018, train_acc: 0.9996 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0022, train_acc: 0.9995 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0018, train_acc: 0.9996 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:05
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0010, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0011, train_acc: 0.9998 test_loss: 0.0001, test_acc: 1.0000, best: 1.0000, time: 0:02:06
 Fold 9 Best Accuracy: 1.0000

---------------- FOLD 10/10 ----------------
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DataParallel                             [64, 10]                  --
├─VGG: 1-1                               [64, 10]                  --
│    └─Sequential: 2-1                   [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          576
│    │    └─ReLU: 3-2                    [64, 64, 64, 64]          --
│    │    └─Dropout: 3-3                 [64, 64, 64, 64]          --
│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864
│    │    └─ReLU: 3-5                    [64, 64, 64, 64]          --
│    │    └─AvgPool2d: 3-6               [64, 64, 32, 32]          --
│    │    └─Conv2d: 3-7                  [64, 128, 32, 32]         73,728
│    │    └─ReLU: 3-8                    [64, 128, 32, 32]         --
│    │    └─Dropout: 3-9                 [64, 128, 32, 32]         --
│    │    └─Conv2d: 3-10                 [64, 128, 32, 32]         147,456
│    │    └─ReLU: 3-11                   [64, 128, 32, 32]         --
│    │    └─AvgPool2d: 3-12              [64, 128, 16, 16]         --
│    │    └─Conv2d: 3-13                 [64, 256, 16, 16]         294,912
│    │    └─ReLU: 3-14                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-15                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-16                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-17                   [64, 256, 16, 16]         --
│    │    └─Dropout: 3-18                [64, 256, 16, 16]         --
│    │    └─Conv2d: 3-19                 [64, 256, 16, 16]         589,824
│    │    └─ReLU: 3-20                   [64, 256, 16, 16]         --
│    │    └─AvgPool2d: 3-21              [64, 256, 8, 8]           --
│    │    └─Conv2d: 3-22                 [64, 512, 8, 8]           1,179,648
│    │    └─ReLU: 3-23                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-24                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-25                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-26                   [64, 512, 8, 8]           --
│    │    └─Dropout: 3-27                [64, 512, 8, 8]           --
│    │    └─Conv2d: 3-28                 [64, 512, 8, 8]           2,359,296
│    │    └─ReLU: 3-29                   [64, 512, 8, 8]           --
│    │    └─AvgPool2d: 3-30              [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-31                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-32                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-33                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-34                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-35                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-36                [64, 512, 4, 4]           --
│    │    └─Conv2d: 3-37                 [64, 512, 4, 4]           2,359,296
│    │    └─ReLU: 3-38                   [64, 512, 4, 4]           --
│    │    └─Dropout: 3-39                [64, 512, 4, 4]           --
│    └─Sequential: 2-2                   [64, 10]                  --
│    │    └─Linear: 3-40                 [64, 4096]                33,554,432
│    │    └─ReLU: 3-41                   [64, 4096]                --
│    │    └─Dropout: 3-42                [64, 4096]                --
│    │    └─Linear: 3-43                 [64, 4096]                16,777,216
│    │    └─ReLU: 3-44                   [64, 4096]                --
│    │    └─Dropout: 3-45                [64, 4096]                --
│    │    └─Linear: 3-46                 [64, 10]                  40,960
==========================================================================================
Total params: 65,081,920
Trainable params: 65,081,920
Non-trainable params: 0
Total mult-adds (G): 83.10
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 570.43
Params size (MB): 260.33
Estimated Total Size (MB): 831.81
==========================================================================================
 Epoch: 1, lr: 1.0e-02, train_loss: 2.2521, train_acc: 0.1001 test_loss: 2.0984, test_acc: 0.1320, best: 0.1320, time: 0:02:30
 Epoch: 2, lr: 1.0e-02, train_loss: 2.0028, train_acc: 0.1906 test_loss: 1.9061, test_acc: 0.2420, best: 0.2420, time: 0:02:29
 Epoch: 3, lr: 1.0e-02, train_loss: 1.3672, train_acc: 0.4470 test_loss: 0.7408, test_acc: 0.7210, best: 0.7210, time: 0:02:30
 Epoch: 4, lr: 1.0e-02, train_loss: 0.6124, train_acc: 0.7714 test_loss: 0.4849, test_acc: 0.7995, best: 0.7995, time: 0:02:30
 Epoch: 5, lr: 1.0e-02, train_loss: 1.1828, train_acc: 0.5589 test_loss: 0.8327, test_acc: 0.7000, best: 0.7995, time: 0:02:17
 Epoch: 6, lr: 1.0e-02, train_loss: 0.4983, train_acc: 0.8210 test_loss: 0.2303, test_acc: 0.9095, best: 0.9095, time: 0:02:12
 Epoch: 7, lr: 1.0e-02, train_loss: 0.1911, train_acc: 0.9345 test_loss: 0.1186, test_acc: 0.9670, best: 0.9670, time: 0:02:29
 Epoch: 8, lr: 1.0e-02, train_loss: 0.1087, train_acc: 0.9655 test_loss: 0.0312, test_acc: 0.9865, best: 0.9865, time: 0:02:29
 Epoch: 9, lr: 1.0e-02, train_loss: 0.0676, train_acc: 0.9792 test_loss: 0.0189, test_acc: 0.9920, best: 0.9920, time: 0:02:30
 Epoch: 10, lr: 1.0e-02, train_loss: 0.0438, train_acc: 0.9869 test_loss: 0.0097, test_acc: 0.9955, best: 0.9955, time: 0:02:29
 Epoch: 11, lr: 1.0e-02, train_loss: 0.0371, train_acc: 0.9889 test_loss: 0.0100, test_acc: 0.9970, best: 0.9970, time: 0:02:30
 Epoch: 12, lr: 1.0e-02, train_loss: 0.0368, train_acc: 0.9894 test_loss: 0.0169, test_acc: 0.9940, best: 0.9970, time: 0:02:16
 Epoch: 13, lr: 1.0e-02, train_loss: 0.0339, train_acc: 0.9899 test_loss: 0.0230, test_acc: 0.9950, best: 0.9970, time: 0:02:15
 Epoch: 14, lr: 1.0e-02, train_loss: 0.0165, train_acc: 0.9952 test_loss: 0.0095, test_acc: 0.9970, best: 0.9970, time: 0:02:16
 Epoch: 15, lr: 1.0e-02, train_loss: 0.0234, train_acc: 0.9934 test_loss: 0.0128, test_acc: 0.9965, best: 0.9970, time: 0:02:15
 Epoch: 16, lr: 1.0e-02, train_loss: 0.0198, train_acc: 0.9946 test_loss: 0.0081, test_acc: 0.9995, best: 0.9995, time: 0:02:24
 Epoch: 17, lr: 1.0e-02, train_loss: 0.0136, train_acc: 0.9966 test_loss: 0.0063, test_acc: 0.9985, best: 0.9995, time: 0:02:15
 Epoch: 18, lr: 1.0e-02, train_loss: 0.0170, train_acc: 0.9951 test_loss: 0.0076, test_acc: 0.9975, best: 0.9995, time: 0:02:16
 Epoch: 19, lr: 1.0e-02, train_loss: 0.0160, train_acc: 0.9951 test_loss: 0.0049, test_acc: 0.9990, best: 0.9995, time: 0:02:15
 Epoch: 20, lr: 1.0e-02, train_loss: 0.0093, train_acc: 0.9973 test_loss: 0.0061, test_acc: 0.9990, best: 0.9995, time: 0:02:11
 Epoch: 21, lr: 1.0e-02, train_loss: 0.0069, train_acc: 0.9986 test_loss: 0.0009, test_acc: 0.9995, best: 0.9995, time: 0:02:16
 Epoch: 22, lr: 1.0e-02, train_loss: 0.0134, train_acc: 0.9959 test_loss: 0.0025, test_acc: 0.9990, best: 0.9995, time: 0:02:15
 Epoch: 23, lr: 1.0e-02, train_loss: 0.0090, train_acc: 0.9975 test_loss: 0.0032, test_acc: 0.9995, best: 0.9995, time: 0:02:15
 Epoch: 24, lr: 1.0e-02, train_loss: 0.0087, train_acc: 0.9978 test_loss: 0.0004, test_acc: 1.0000, best: 1.0000, time: 0:02:29
 Epoch: 25, lr: 1.0e-02, train_loss: 0.0072, train_acc: 0.9980 test_loss: 0.0035, test_acc: 0.9990, best: 1.0000, time: 0:02:23
 Epoch: 26, lr: 1.0e-02, train_loss: 0.0039, train_acc: 0.9989 test_loss: 0.0003, test_acc: 1.0000, best: 1.0000, time: 0:02:16
 Epoch: 27, lr: 1.0e-02, train_loss: 0.0060, train_acc: 0.9981 test_loss: 0.0004, test_acc: 1.0000, best: 1.0000, time: 0:02:16
 Epoch: 28, lr: 1.0e-02, train_loss: 0.0097, train_acc: 0.9975 test_loss: 0.0007, test_acc: 1.0000, best: 1.0000, time: 0:02:16
 Epoch: 29, lr: 1.0e-02, train_loss: 0.0053, train_acc: 0.9985 test_loss: 0.0042, test_acc: 0.9985, best: 1.0000, time: 0:02:11
 Epoch: 30, lr: 1.0e-03, train_loss: 0.0033, train_acc: 0.9993 test_loss: 0.0020, test_acc: 0.9990, best: 1.0000, time: 0:02:11
 Epoch: 31, lr: 1.0e-03, train_loss: 0.0019, train_acc: 0.9993 test_loss: 0.0042, test_acc: 0.9985, best: 1.0000, time: 0:02:15
 Epoch: 32, lr: 1.0e-03, train_loss: 0.0021, train_acc: 0.9994 test_loss: 0.0022, test_acc: 0.9990, best: 1.0000, time: 0:02:16
 Epoch: 33, lr: 1.0e-03, train_loss: 0.0021, train_acc: 0.9996 test_loss: 0.0023, test_acc: 0.9990, best: 1.0000, time: 0:02:15
 Epoch: 34, lr: 1.0e-03, train_loss: 0.0021, train_acc: 0.9995 test_loss: 0.0029, test_acc: 0.9990, best: 1.0000, time: 0:02:15
 Epoch: 35, lr: 1.0e-03, train_loss: 0.0019, train_acc: 0.9995 test_loss: 0.0026, test_acc: 0.9990, best: 1.0000, time: 0:02:16
 Epoch: 36, lr: 1.0e-03, train_loss: 0.0017, train_acc: 0.9993 test_loss: 0.0009, test_acc: 0.9995, best: 1.0000, time: 0:02:15
 Epoch: 37, lr: 1.0e-03, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.0011, test_acc: 0.9995, best: 1.0000, time: 0:02:11
 Epoch: 38, lr: 1.0e-03, train_loss: 0.0020, train_acc: 0.9994 test_loss: 0.0010, test_acc: 0.9995, best: 1.0000, time: 0:02:23
 Epoch: 39, lr: 1.0e-03, train_loss: 0.0022, train_acc: 0.9994 test_loss: 0.0012, test_acc: 0.9995, best: 1.0000, time: 0:02:17
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0019, train_acc: 0.9996 test_loss: 0.0010, test_acc: 0.9990, best: 1.0000, time: 0:02:16
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0020, train_acc: 0.9994 test_loss: 0.0011, test_acc: 0.9990, best: 1.0000, time: 0:02:16
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0017, train_acc: 0.9997 test_loss: 0.0012, test_acc: 0.9990, best: 1.0000, time: 0:02:15
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0015, train_acc: 0.9997 test_loss: 0.0012, test_acc: 0.9990, best: 1.0000, time: 0:02:16
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0012, train_acc: 0.9997 test_loss: 0.0014, test_acc: 0.9990, best: 1.0000, time: 0:02:15
 Epoch: 45, lr: 1.0e-05, train_loss: 0.0015, train_acc: 0.9997 test_loss: 0.0014, test_acc: 0.9990, best: 1.0000, time: 0:02:15
 Epoch: 46, lr: 1.0e-05, train_loss: 0.0009, train_acc: 0.9998 test_loss: 0.0014, test_acc: 0.9990, best: 1.0000, time: 0:02:16
 Epoch: 47, lr: 1.0e-05, train_loss: 0.0009, train_acc: 0.9999 test_loss: 0.0014, test_acc: 0.9990, best: 1.0000, time: 0:02:15
 Epoch: 48, lr: 1.0e-05, train_loss: 0.0011, train_acc: 0.9997 test_loss: 0.0013, test_acc: 0.9990, best: 1.0000, time: 0:02:15
 Epoch: 49, lr: 1.0e-05, train_loss: 0.0015, train_acc: 0.9996 test_loss: 0.0013, test_acc: 0.9990, best: 1.0000, time: 0:02:16
 Epoch: 50, lr: 1.0e-05, train_loss: 0.0016, train_acc: 0.9996 test_loss: 0.0013, test_acc: 0.9990, best: 1.0000, time: 0:02:15
 Fold 10 Best Accuracy: 1.0000

================ CROSS VALIDATION SUMMARY ================
 Average Accuracy over 10 folds: 0.9999
 Fold 1: 1.0000
 Fold 2: 0.9990
 Fold 3: 1.0000
 Fold 4: 1.0000
 Fold 5: 1.0000
 Fold 6: 1.0000
 Fold 7: 1.0000
 Fold 8: 0.9995
 Fold 9: 1.0000
 Fold 10: 1.0000